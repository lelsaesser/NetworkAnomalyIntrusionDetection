{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly-based network intrusion detection\n",
    "#### Algorithm comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_DATA_PATH = \"C:\\\\Users\\\\Lucas\\\\Documents\\\\Datasets\\\\Network Intrusion Detection\\\\intrusion-detection_alternative\\\\X_train.csv\"\n",
    "TRAIN_LABELS_PATH = \"C:\\\\Users\\\\Lucas\\\\Documents\\\\Datasets\\\\Network Intrusion Detection\\\\intrusion-detection_alternative\\\\y_train.csv\"\n",
    "TEST_DATA_PATH = \"C:\\\\Users\\\\Lucas\\\\Documents\\\\Datasets\\\\Network Intrusion Detection\\\\intrusion-detection_alternative\\\\X_test.csv\"\n",
    "TEST_LABELS_PATH = \"C:\\\\Users\\\\Lucas\\\\Documents\\\\Datasets\\\\Network Intrusion Detection\\\\intrusion-detection_alternative\\\\y_test.csv\"\n",
    "\n",
    "# second dataset\n",
    "TRAIN_DATA_TWO_PATH = \"C:\\\\Users\\\\Lucas\\\\Documents\\\\Datasets\\\\Network Intrusion Detection\\\\intrusion-detection_alternative\\\\X_train2.csv\"\n",
    "TRAIN_LABELS_TWO_PATH = \"C:\\\\Users\\\\Lucas\\\\Documents\\\\Datasets\\\\Network Intrusion Detection\\\\intrusion-detection_alternative\\\\y_train2.csv\"\n",
    "TEST_DATA_TWO_PATH = \"C:\\\\Users\\\\Lucas\\\\Documents\\\\Datasets\\\\Network Intrusion Detection\\\\intrusion-detection_alternative\\\\X_test2.csv\"\n",
    "TEST_LABELS_TWO_PATH = \"C:\\\\Users\\\\Lucas\\\\Documents\\\\Datasets\\\\Network Intrusion Detection\\\\intrusion-detection_alternative\\\\y_test2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "# First Dataset - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "#1. Read csv data\n",
    "X_train_csv = pd.read_csv(TRAIN_DATA_PATH)\n",
    "y_train_csv = pd.read_csv(TRAIN_LABELS_PATH)\n",
    "\n",
    "X_test_csv = pd.read_csv(TEST_DATA_PATH)\n",
    "y_test_csv = pd.read_csv(TEST_LABELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. store data in numpy array\n",
    "X_train = np.array(X_train_csv)\n",
    "y_train = np.array(y_train_csv)\n",
    "\n",
    "X_test = np.array(X_test_csv)\n",
    "y_test = np.array(y_test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Encode categorical values in train and test data\n",
    "\n",
    "# protocol_type:\n",
    "# icmp = 1\n",
    "# udp = 2\n",
    "# tcp = 3\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if X_train[i][1] == 'icmp':\n",
    "        X_train[i][1] = 1\n",
    "    elif X_train[i][1] == 'udp':\n",
    "        X_train[i][1] = 2\n",
    "    elif X_train[i][1] == 'tcp':\n",
    "        X_train[i][1] = 3\n",
    "        \n",
    "for i in range(len(X_test)):\n",
    "    if X_test[i][1] == 'icmp':\n",
    "        X_test[i][1] = 1\n",
    "    elif X_test[i][1] == 'udp':\n",
    "        X_test[i][1] = 2\n",
    "    elif X_test[i][1] == 'tcp':\n",
    "        X_test[i][1] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "# Second Dataset - Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read csv data\n",
    "X_train_csv_two = pd.read_csv(TRAIN_DATA_TWO_PATH)\n",
    "y_train_csv_two = pd.read_csv(TRAIN_LABELS_TWO_PATH)\n",
    "\n",
    "X_test_csv_two = pd.read_csv(TEST_DATA_TWO_PATH)\n",
    "y_test_csv_two = pd.read_csv(TEST_LABELS_TWO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. store data in numpy array\n",
    "X_train_two = np.array(X_train_csv_two)\n",
    "y_train_two = np.array(y_train_csv_two)\n",
    "\n",
    "X_test_two = np.array(X_test_csv_two)\n",
    "y_test_two = np.array(y_test_csv_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Encode categorical values in train and test data\n",
    "\n",
    "# protocol_type:\n",
    "# icmp = 1\n",
    "# udp = 2\n",
    "# tcp = 3\n",
    "\n",
    "for i in range(len(X_train_two)):\n",
    "    if X_train_two[i][1] == 'icmp':\n",
    "        X_train_two[i][1] = 1\n",
    "    elif X_train_two[i][1] == 'udp':\n",
    "        X_train_two[i][1] = 2\n",
    "    elif X_train_two[i][1] == 'tcp':\n",
    "        X_train_two[i][1] = 3\n",
    "        \n",
    "for i in range(len(X_test_two)):\n",
    "    if X_test_two[i][1] == 'icmp':\n",
    "        X_test_two[i][1] = 1\n",
    "    elif X_test_two[i][1] == 'udp':\n",
    "        X_test_two[i][1] = 2\n",
    "    elif X_test_two[i][1] == 'tcp':\n",
    "        X_test_two[i][1] = 3\n",
    "        \n",
    "# service:\n",
    "\n",
    "for i in range(len(X_train_two)):\n",
    "    if X_train_two[i][2] == 'ftp_data':\n",
    "        X_train_two[i][2] == 1\n",
    "    elif X_train_two[i][2] == 'other':\n",
    "        X_train_two[i][2] == 2\n",
    "    elif X_train_two[i][2] == 'other':\n",
    "        X_train_two[i][2] == 2\n",
    "    elif X_train_two[i][2] == 'other':\n",
    "        X_train_two[i][2] == 2\n",
    "    elif X_train_two[i][2] == 'other':\n",
    "        X_train_two[i][2] == 2\n",
    "    elif X_train_two[i][2] == 'other':\n",
    "        X_train_two[i][2] == 2\n",
    "        \n",
    "def encodeService(service):\n",
    "    return {\n",
    "        'ftp_data' : 1,\n",
    "        'other' : 2,\n",
    "        'private' : 3,\n",
    "        'http' : 4,\n",
    "        'remote_job' : 5,\n",
    "        'name' : 6,\n",
    "        'netbios_ns' : 7,\n",
    "        'eco_i' : 8,\n",
    "        'mtp' : 9,\n",
    "        'telnet' : 10,\n",
    "        'finger' : 11,\n",
    "        'domain_u' : 12,\n",
    "        'supdup' : 13,\n",
    "        'uucp_path' : 14,\n",
    "        'Z39_50' : 15,\n",
    "        'smtp' : 16,\n",
    "        'csnet_ns' : 17,\n",
    "        'uucp' : 18,\n",
    "        'netbios_dgm' : 19,\n",
    "        'urp_i' : 20,\n",
    "        'auth' : 21,\n",
    "        'domain' : 22,\n",
    "        'ftp' : 23,\n",
    "        'bgp' : 24,\n",
    "        'ldap' : 25,\n",
    "        'ecr_i' : 26,\n",
    "        'gopher' : 27,\n",
    "        'vmnet' : 28,\n",
    "        'systat' : 29,\n",
    "        'http_443' : 30,\n",
    "        'efs' : 31,\n",
    "        'whois' : 32,\n",
    "        'imap4' : 33,\n",
    "        'echo' : 34,\n",
    "        'klogin' : 35,\n",
    "        'link' : 36,\n",
    "        'sunrpc' : 37,\n",
    "        'login' : 38,\n",
    "        'kshell' : 39,\n",
    "        'sql_net' : 40,\n",
    "        'time' : 41,\n",
    "        'hostnames' : 42,\n",
    "        'exec' : 43,\n",
    "        'ntp_u' : 44,\n",
    "        'discard' : 45,\n",
    "        'nntp' : 46,\n",
    "        'courier' : 47,\n",
    "        'ctf' : 48,\n",
    "        'ssh' : 49,\n",
    "        'daytime' : 50,\n",
    "        'shell' : 51,\n",
    "        'netstat' : 52,\n",
    "        'pop_3' : 53,\n",
    "        'nnsp' : 54,\n",
    "        'IRC' : 55,\n",
    "        'pop_2' : 56,\n",
    "        'printer' : 57,\n",
    "        'tim_i' : 58,\n",
    "        'pm_dump' : 59,\n",
    "        'red_i' : 60,\n",
    "        'netbios_ssn' : 61,\n",
    "        'rje' : 62,\n",
    "        'X11' : 63,\n",
    "        'urh_i' : 64,\n",
    "        'http_8001' : 65,\n",
    "        'iso_tsap' : 66\n",
    "    }[service]\n",
    "\n",
    "encoding = 0\n",
    "for i in range(len(X_train_two)):\n",
    "    encoding = encodeService(X_train_two[i][2])\n",
    "    \n",
    "    if encoding != 0:\n",
    "        X_train_two[i][2] = encoding\n",
    "    else:\n",
    "        print(\"encoding error\")\n",
    "        break\n",
    "        \n",
    "for i in range(len(X_test_two)):\n",
    "    encoding = encodeService(X_test_two[i][2])\n",
    "    \n",
    "    if encoding != 0:\n",
    "        X_test_two[i][2] = encoding\n",
    "    else:\n",
    "        print(\"encoding error\")\n",
    "        break\n",
    "\n",
    "def encodeFlag(flag):\n",
    "    return {\n",
    "        'SF' : 1,\n",
    "        'S0' : 2,\n",
    "        'REJ' : 3,\n",
    "        'RSTR' : 4,\n",
    "        'SH' : 5,\n",
    "        'RSTO' : 6,\n",
    "        'S1' : 7,\n",
    "        'RSTOS0' : 8,\n",
    "        'S3' : 9,\n",
    "        'S2' : 10,\n",
    "        'OTH' : 11,\n",
    "    }[flag]\n",
    "\n",
    "encoding = 0\n",
    "for i in range(len(X_train_two)):\n",
    "    encoding = encodeFlag(X_train_two[i][3])\n",
    "    \n",
    "    if encoding != 0:\n",
    "        X_train_two[i][3] = encoding\n",
    "    else:\n",
    "        print(\"encoding error\")\n",
    "        break\n",
    "    \n",
    "for i in range(len(X_test_two)):\n",
    "    encoding = encodeFlag(X_test_two[i][3])\n",
    "    \n",
    "    if encoding != 0:\n",
    "        X_test_two[i][3] = encoding\n",
    "    else:\n",
    "        print(\"encoding error\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "# First Dataset - Network Anomaly Detection with attack prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Random Forest Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. define classifier\n",
    "rf_clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 train classifier\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 predict test data\n",
    "rf_predictions = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7492 out of 10000 samples correct classified ( 74.92 %)\n"
     ]
    }
   ],
   "source": [
    "#7 validate results\n",
    "count = 0\n",
    "for i, j in zip(rf_predictions, y_test):\n",
    "    if i == j:\n",
    "        count += 1\n",
    "\n",
    "print(count, \"out of\", len(rf_predictions), \"samples correct classified (\", count/len(rf_predictions)*100, \"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3394 out of 5671 total attacks detected ( 59.84835126080057 %)\n"
     ]
    }
   ],
   "source": [
    "total_attacks = (y_test != 'normal').sum()\n",
    "count = 0\n",
    "for i, j in zip(rf_predictions, y_test):\n",
    "    if i != 'normal' and j != 'normal':\n",
    "        count += 1\n",
    "            \n",
    "print(count, \"out of\", total_attacks, \"total attacks detected (\", count/total_attacks*100, \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "X_train_norm = preprocessing.scale(X_train)\n",
    "X_test_norm = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classifier\n",
    "svc_clf = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_predictions = svc_clf.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7755 out of 10000 samples correct classified ( 77.55 %)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, j in zip(svc_predictions, y_test):\n",
    "    if i == j:\n",
    "        count += 1\n",
    "\n",
    "print(count, \"out of\", len(svc_predictions), \"samples correct classified (\", count/len(svc_predictions)*100, \"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3832 out of 5671 total attacks detected ( 67.57185681537648 %)\n"
     ]
    }
   ],
   "source": [
    "total_attacks = (y_test != 'normal').sum()\n",
    "count = 0\n",
    "for i, j in zip(svc_predictions, y_test):\n",
    "    if i != 'normal' and j != 'normal':\n",
    "        count += 1\n",
    "            \n",
    "print(count, \"out of\", total_attacks, \"total attacks detected (\", count/total_attacks*100, \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "### Gradient Boosting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# xgboost needs the labels to be encoded as well\n",
    "# normal = 1\n",
    "# dos = 2\n",
    "# r2l = 3\n",
    "# probe = 4\n",
    "# u2r = 5\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == 'normal':\n",
    "        y_train[i] = 1\n",
    "    elif y_train[i] == 'dos':\n",
    "        y_train[i] = 2\n",
    "    elif y_train[i] == 'r2l':\n",
    "        y_train[i] = 3\n",
    "    elif y_train[i] == 'probe':\n",
    "        y_train[i] = 4\n",
    "    elif y_train[i] == 'u2r':\n",
    "        y_train[i] = 5\n",
    "        \n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == 'normal':\n",
    "        y_test[i] = 1\n",
    "    elif y_test[i] == 'dos':\n",
    "        y_test[i] = 2\n",
    "    elif y_test[i] == 'r2l':\n",
    "        y_test[i] = 3\n",
    "    elif y_test[i] == 'probe':\n",
    "        y_test[i] = 4\n",
    "    elif y_test[i] == 'u2r':\n",
    "        y_test[i] = 5\n",
    "        \n",
    "#3 normalize data\n",
    "X_train_norm = preprocessing.scale(X_train)\n",
    "X_test_norm = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Machine\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X_train_norm, label=X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define xgb classifier\n",
    "xg_clf = xgb.XGBClassifier(learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.5)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit classifier\n",
    "xg_clf.fit(X_train_norm, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb_predictions = xg_clf.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7407 out of 10000 samples correct classified ( 74.07000000000001 %)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, j in zip(xgb_predictions, y_test):\n",
    "    if i == j:\n",
    "        count += 1\n",
    "\n",
    "print(count, \"out of\", len(xgb_predictions), \"samples correct classified (\", count/len(xgb_predictions)*100, \"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4065 out of 5671 total attacks detected ( 71.68047963322165 %)\n"
     ]
    }
   ],
   "source": [
    "total_attacks = (y_test != 1).sum()\n",
    "count = 0\n",
    "for i, j in zip(xgb_predictions, y_test):\n",
    "    if i != 1 and j != 1:\n",
    "        count += 1\n",
    "            \n",
    "print(count, \"out of\", total_attacks, \"total attacks detected (\", count/total_attacks*100, \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "# Second Dataset - Network Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. define classifier\n",
    "rf_clf_two = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. train classifier\n",
    "rf_clf_two.fit(X_train_two, y_train_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. predict test data\n",
    "rf_predictions_two = rf_clf_two.predict(X_test_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5182 out of 5194 samples correct classified ( 99.76896418944936 %)\n"
     ]
    }
   ],
   "source": [
    "# 4. validate results\n",
    "count = 0\n",
    "for i, j in zip(rf_predictions_two, y_test_two):\n",
    "    if i == j:\n",
    "        count += 1\n",
    "\n",
    "print(count, \"out of\", len(rf_predictions_two), \"samples correct classified (\", count/len(rf_predictions_two)*100, \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# normalize data\n",
    "X_train_two_norm = preprocessing.scale(X_train_two)\n",
    "X_test_two_norm = preprocessing.scale(X_test_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classifier\n",
    "svc_clf_two = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf_two.fit(X_train_two_norm, y_train_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_predictions_two = svc_clf_two.predict(X_test_two_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5116 out of 5194 samples correct classified ( 98.49826723142087 %)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, j in zip(svc_predictions_two, y_test_two):\n",
    "    if i == j:\n",
    "        count += 1\n",
    "\n",
    "print(count, \"out of\", len(svc_predictions_two), \"samples correct classified (\", count/len(svc_predictions_two)*100, \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost label encoding\n",
    "# normal = 0\n",
    "# anomaly = 1\n",
    "\n",
    "for i in range(len(y_train_two)):\n",
    "    if y_train_two[i] == 'normal':\n",
    "        y_train_two[i] = 0\n",
    "    elif y_train_two[i] == 'anomaly':\n",
    "        y_train_two[i] = 1\n",
    "        \n",
    "for i in range(len(y_test_two)):\n",
    "    if y_test_two[i] == 'normal':\n",
    "        y_test_two[i] = 0\n",
    "    elif y_test_two[i] == 'anomaly':\n",
    "        y_test_two[i] = 1\n",
    "        \n",
    "X_train_norm_two = preprocessing.scale(X_train_two)\n",
    "X_test_norm_two = preprocessing.scale(X_test_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define xgb classifier\n",
    "xg_clf_two = xgb.XGBClassifier(learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.5)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit classifier\n",
    "xg_clf_two.fit(X_train_norm_two, y_train_two.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb_predictions_two = xg_clf_two.predict(X_test_norm_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4908 out of 5194 samples correct classified ( 94.49364651520986 %)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, j in zip(xgb_predictions_two, y_test_two):\n",
    "    if i == j:\n",
    "        count += 1\n",
    "\n",
    "print(count, \"out of\", len(xgb_predictions_two), \"samples correct classified (\", count/len(xgb_predictions_two)*100, \"%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
